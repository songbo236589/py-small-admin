# ===================================================================
# 生产环境配置示例
# ===================================================================
# 使用说明:
# 1. 复制此文件为 .env.production: cp .env.production.example .env.production
# 2. 根据生产环境需求修改配置（特别是密码、密钥等敏感信息）
# 3. 确保所有敏感信息都已修改为强密码
# 4. 此文件不应提交到版本控制系统
# ===================================================================

# ===================================================================
# 应用基础配置
# ===================================================================

# 应用名称（用于日志、文档等显示）
APP_NAME="Py Small Admin"

# 运行环境，可选: development(开发)、production(生产)、testing(测试)
# 生产环境必须设置为 production
APP_ENV=production

# 调试模式（true=显示详细错误信息、禁用安全限制，生产环境必须设为false）
APP_DEBUG=false

# 应用版本号（用于API版本控制、响应头等）
APP_VERSION="1.0.0"

# 应用描述（用于API文档生成）
APP_DESCRIPTION="Py Small Admin 服务"

# 服务监听地址（0.0.0.0=监听所有网卡，127.0.0.1=仅本机访问）
APP_HOST=0.0.0.0

# 服务监听端口（1-65535，避免使用系统保留端口1-1023）
APP_PORT=8009

# 代码自动重载（开发环境true=代码修改后自动重启，生产环境必须设为false）
APP_RELOAD=false

# API路径前缀（所有API路由都会添加此前缀，如: /api/users）
APP_API_PREFIX="/api"

# ===================================================================
# API文档配置
# ===================================================================

# 是否启用API文档（true=启用Swagger UI和ReDoc，生产环境建议关闭或通过IP白名单限制访问）
APP_DOCS_ENABLED=false

# Swagger UI文档路径（访问地址: http://host:port/docs）
APP_DOCS_URL="/docs"

# OpenAPI JSON规范路径（用于生成客户端SDK等）
APP_OPENAPI_URL="/openapi.json"

# ===================================================================
# 跨域配置 (CORS)
# ===================================================================

# 是否允许所有来源（true=允许任何域名访问，生产环境必须设为false并指定具体域名）
APP_CORS_ALLOW_ALL=false

# 允许的来源列表（JSON格式，生产环境必须配置实际允许的域名）
APP_CORS_ORIGINS=["https://yourdomain.com"]

# 允许的HTTP方法（JSON格式，建议明确指定需要的方法，不使用通配符）
APP_CORS_METHODS=["GET", "POST", "PUT", "DELETE", "OPTIONS"]

# 允许的请求头（JSON格式，建议明确指定，避免使用通配符）
APP_CORS_HEADERS=["Content-Type", "Authorization"]

# 时区设置（影响日志时间、定时任务时间等，推荐与服务器时区一致）
APP_TIMEZONE="Asia/Shanghai"

# Admin X API Key（管理后台API密钥，用于验证管理端请求，生产环境必须使用强密钥！）
APP_ADMIN_X_API_KEY="CHANGE_THIS_TO_STRONG_KEY_IN_PRODUCTION"

# ===================================================================
# 默认管理员账号配置
# ===================================================================

# 生产环境请修改为强密码
APP_DEFAULT_ADMIN_USERNAME="admin"
APP_DEFAULT_ADMIN_PASSWORD="CHANGE_THIS_TO_STRONG_PASSWORD_IN_PRODUCTION"

# ===================================================================
# 日志配置
# ===================================================================

# 日志级别，可选: DEBUG(调试)、INFO(信息)、WARNING(警告)、ERROR(错误)、CRITICAL(严重)
# 生产环境建议使用 WARNING 或 ERROR 以减少日志量
LOG_LEVEL=WARNING

# 是否启用控制台日志输出（生产环境建议false，仅输出到文件）
LOG_CONSOLE=false

# 日志文件路径（支持loguru格式，{time:YYYY-MM-DD}=按日期分割文件）
LOG_FILE_PATH="logs/{time:YYYY-MM-DD}.log"

# 日志文件轮转时间（每天何时创建新日志文件，00:00=午夜）
LOG_ROTATION="00:00"

# 日志文件保留时间（超过此时长的日志将被自动删除，生产环境建议保留更久以便审计）
LOG_RETENTION="90 days"

# 日志文件压缩格式（压缩旧日志以节省空间，可选: zip、gz、tar、空字符串(不压缩)）
LOG_COMPRESSION="zip"

# ===================================================================
# 数据库配置
# ===================================================================

# 默认数据库连接类型（可选: mysql、postgresql、sqlite等）
DB_DEFAULT=mysql

# ========================================
# MySQL 连接配置
# ========================================

# MySQL 主机地址（生产环境使用独立数据库服务器地址或内网IP）
DB_CONNECTIONS__MYSQL__HOST=127.0.0.1

# MySQL 端口（默认3306）
DB_CONNECTIONS__MYSQL__PORT=3306

# MySQL 数据库名称
DB_CONNECTIONS__MYSQL__DATABASE=fastapi_db

# MySQL 用户名（生产环境必须使用专用账号，禁止使用root！）
DB_CONNECTIONS__MYSQL__USERNAME=fastapi_user

# MySQL 密码（生产环境必须使用强密码！）
DB_CONNECTIONS__MYSQL__PASSWORD=CHANGE_MYSQL_PASSWORD_IN_PRODUCTION

# MySQL 字符集（utf8mb4支持emoji等4字节字符）
DB_CONNECTIONS__MYSQL__CHARSET=utf8mb4

# MySQL 排序规则（unicode_ci不区分大小写，支持多语言）
DB_CONNECTIONS__MYSQL__COLLATION=utf8mb4_unicode_ci

# MySQL 表前缀（用于多应用共享数据库，避免表名冲突）
DB_CONNECTIONS__MYSQL__PREFIX=fa_

# ========================================
# Redis 默认连接配置
# ========================================

# Redis 主机地址（生产环境使用独立Redis服务器地址或内网IP）
DB_REDIS__DEFAULT__HOST=127.0.0.1

# Redis 端口（默认6379）
DB_REDIS__DEFAULT__PORT=6379

# Redis 用户名（Redis 6.0+支持ACL，老版本留空）
DB_REDIS__DEFAULT__USERNAME=default

# Redis 密码（生产环境必须设置强密码！）
DB_REDIS__DEFAULT__PASSWORD=CHANGE_REDIS_PASSWORD_IN_PRODUCTION

# Redis 数据库编号（0-15，不同应用使用不同DB避免数据冲突）
DB_REDIS__DEFAULT__DATABASE=0

# Redis 键前缀（用于区分不同应用的数据）
DB_REDIS__DEFAULT__PREFIX=redis_default_

# Redis 连接池最大连接数（生产环境建议根据并发量调整，通常100-200）
DB_REDIS__DEFAULT__MAX_CONNECTIONS=100

# 超时是否自动重试（true=命令超时后自动重试）
DB_REDIS__DEFAULT__RETRY_ON_TIMEOUT=true

# Socket 读写超时时间（秒，超过此时长未响应则超时）
DB_REDIS__DEFAULT__SOCKET_TIMEOUT=5

# Socket 连接超时时间（秒，连接建立的最大等待时间）
DB_REDIS__DEFAULT__SOCKET_CONNECT_TIMEOUT=5

# 健康检查间隔（秒，定期检查连接是否可用）
DB_REDIS__DEFAULT__HEALTH_CHECK_INTERVAL=30

# ========================================
# Redis 缓存连接配置
# ========================================

# Redis 主机地址（通常与DEFAULT使用同一实例）
DB_REDIS__CACHE__HOST=127.0.0.1

# Redis 端口
DB_REDIS__CACHE__PORT=6379

# Redis 用户名
DB_REDIS__CACHE__USERNAME=default

# Redis 密码（生产环境必须设置强密码！）
DB_REDIS__CACHE__PASSWORD=CHANGE_REDIS_PASSWORD_IN_PRODUCTION

# Redis 数据库编号（使用不同DB与业务数据分离，推荐1用于缓存）
DB_REDIS__CACHE__DATABASE=1

# Redis 键前缀（缓存数据专用前缀，便于清理）
DB_REDIS__CACHE__PREFIX=cache_

# Redis 连接池最大连接数（生产环境建议100-200）
DB_REDIS__CACHE__MAX_CONNECTIONS=100

# 超时是否自动重试
DB_REDIS__CACHE__RETRY_ON_TIMEOUT=true

# Socket 读写超时时间（秒）
DB_REDIS__CACHE__SOCKET_TIMEOUT=5

# Socket 连接超时时间（秒）
DB_REDIS__CACHE__SOCKET_CONNECT_TIMEOUT=5

# 健康检查间隔（秒）
DB_REDIS__CACHE__HEALTH_CHECK_INTERVAL=30

# ===================================================================
# 缓存配置
# ===================================================================

# 使用的缓存连接名称（对应 DB_REDIS__CACHE__ 配置）
CACHE_CONNECTION=cache

# 默认缓存过期时间（秒），31536000秒 = 365天
CACHE_DEFAULT_TTL=31536000

# 缓存键前缀，用于区分不同应用或环境的缓存
CACHE_KEY_PREFIX=cache

# ===================================================================
# 密码配置
# ===================================================================

# 支持的密码加密算法列表，可选: bcrypt, argon2, pbkdf2_sha256 等
PWD_PASSWORD_SCHEMES=["bcrypt"]

# 默认使用的密码加密算法
PWD_PASSWORD_DEFAULT_SCHEME="bcrypt"

# 是否自动弃用旧算法，"auto" 表示当使用新算法加密时自动标记旧密码为弃用
PWD_PASSWORD_DEPRECATED="auto"

# bcrypt 加密轮数（成本因子），范围 4-31，值越大加密越慢但越安全
# 生产环境建议 12-14（每增加1，加密时间翻倍）
PWD_BCRYPT_ROUNDS=12

# bcrypt 算法标识符，2b 是当前标准版本（另有 2a、2y 等）
PWD_BCRYPT_IDENT="2b"

# bcrypt 盐值大小（固定 22 位，无需修改）
PWD_BCRYPT_SALT_SIZE=22

# 密码哈希截断时是否报错（false 表示自动截断过长密码）
PWD_BCRYPT_TRUNCATE_ERROR=False

# ===================================================================
# JWT认证配置
# ===================================================================

# JWT密钥（用于签名令牌，生产环境必须修改为至少32字符的强密钥！）
JWT_SECRET_KEY="CHANGE_THIS_TO_VERY_STRONG_SECRET_KEY_AT_LEAST_32_CHARACTERS_LONG"

# JWT签名算法，可选: HS256(HMAC-SHA256)、RS256(RSA-SHA256)、ES256等
# 生产环境如需更高安全性，可使用 RS256（非对称加密）
JWT_ALGORITHM="HS256"

# 访问令牌有效期（分钟），过期后需要使用刷新令牌获取新的访问令牌
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# 刷新令牌有效期（天），用于获取新的访问令牌
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# JWT签发者标识，用于验证令牌来源
JWT_ISSUER="fast-api-admin"

# JWT目标受众，用于限制令牌的使用范围
JWT_AUDIENCE="fast-client-admin"

# 是否验证令牌过期时间（生产环境必须开启）
JWT_VERIFY_EXPIRATION=true

# 是否验证令牌签发者（生产环境必须开启）
JWT_VERIFY_ISSUER=true

# 是否验证令牌受众（生产环境必须开启）
JWT_VERIFY_AUDIENCE=true

# 访问令牌类型标识（固定值，无需修改）
JWT_ACCESS_TOKEN_TYPE="access"

# 刷新令牌类型标识（固定值，无需修改）
JWT_REFRESH_TOKEN_TYPE="refresh"

# 是否启用令牌黑名单（启用后登出/刷新的令牌会被加入黑名单）
JWT_ENABLE_BLACKLIST=true

# Redis中黑名单键的前缀
JWT_BLACKLIST_PREFIX="jwt:blacklist:admin:"

# ===================================================================
# 验证码配置
# ===================================================================

CAPTCHA_LENGTH=4
CAPTCHA_WIDTH=120
CAPTCHA_HEIGHT=50
CAPTCHA_FONT_SIZE=28
CAPTCHA_CHAR_TYPE=alphanumeric
CAPTCHA_FONT_PATH=""
CAPTCHA_BACKGROUND_COLOR="[255,255,255]"
CAPTCHA_TEXT_COLOR="[0,0,0]"
CAPTCHA_NOISE_LINE_COUNT=2
CAPTCHA_NOISE_POINT_COUNT=100
CAPTCHA_NOISE_LINE_COLOR_RANGE="[[100,200],[100,200],[100,200]]"
CAPTCHA_NOISE_POINT_COLOR_RANGE="[[150,255],[150,255],[150,255]]"
CAPTCHA_DISTORTION=true
CAPTCHA_DISTORTION_LEVEL=0.1
CAPTCHA_EXPIRE_SECONDS=300
CAPTCHA_REDIS_KEY_PREFIX=captcha:
CAPTCHA_DEFAULT_TYPE=image

# ===================================================================
# 文件上传配置
# ===================================================================

UPLOAD_DIR="./uploads"
UPLOAD_URL_PREFIX="/uploads"
UPLOAD_FILENAME_RULE="uuid"
UPLOAD_PATH_RULE="Y-m-d"

# ===================================================================
# 阿里云 OSS 配置（生产环境建议使用云存储）
# ===================================================================

UPLOAD_OSS_ACCESS_KEY_ID=""
UPLOAD_OSS_ACCESS_KEY_SECRET=""
UPLOAD_OSS_REGION="oss-cn-hangzhou"
UPLOAD_OSS_BUCKET=""
UPLOAD_OSS_ENDPOINT=""
UPLOAD_OSS_INTERNAL_ENDPOINT=""
UPLOAD_OSS_CDN_DOMAIN=""

# ===================================================================
# 腾讯云 COS 配置
# ===================================================================

UPLOAD_COS_SECRET_ID=""
UPLOAD_COS_SECRET_KEY=""
UPLOAD_COS_REGION="ap-guangzhou"
UPLOAD_COS_BUCKET=""
UPLOAD_COS_ENDPOINT=""
UPLOAD_COS_CDN_DOMAIN=""

# ===================================================================
# 七牛云 Kodo 配置
# ===================================================================

UPLOAD_KODO_ACCESS_KEY=""
UPLOAD_KODO_SECRET_KEY=""
UPLOAD_KODO_BUCKET=""
UPLOAD_KODO_REGION="z0"
UPLOAD_KODO_DOMAIN=""

# ===================================================================
# Celery + RabbitMQ 配置
# ===================================================================

# ========== Broker 配置 ==========

# 消息代理 URL（格式: amqp://用户名:密码@主机:端口/虚拟主机）
# 生产环境必须修改密码！
CELERY_BROKER_URL="amqp://admin:CHANGE_RABBITMQ_PASSWORD_IN_PRODUCTION@localhost:5672//"

# 连接失败时是否自动重试（true=连接断开后自动尝试重连）
CELERY_BROKER_CONNECTION_RETRY=true

# 启动时连接失败是否重试（true=应用启动时Broker不可用则继续重试）
CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP=true

# 最大重试次数（连接失败后的最大重试次数，超过则放弃）
CELERY_BROKER_CONNECTION_MAX_RETRIES=5

# 重试延迟时间（秒）
CELERY_BROKER_CONNECTION_RETRY_DELAY=5

# 是否使用 SSL 连接 RabbitMQ（生产环境强烈建议开启以确保数据传输安全）
CELERY_BROKER_USE_SSL=false

# Broker 传输选项（JSON格式）
# heartbeat: 心跳间隔（秒），用于检测连接是否存活
# socket_timeout: socket超时时间（秒）
# socket_keepalive: 是否启用TCP keepalive
CELERY_BROKER_TRANSPORT_OPTIONS={"heartbeat": 60, "socket_timeout": 30, "socket_keepalive": true}

# ========== Result Backend 配置 ==========

# 任务结果存储 URL
CELERY_RESULT_BACKEND="redis://default:CHANGE_REDIS_PASSWORD_IN_PRODUCTION@127.0.0.1:6379/0"

# 任务结果过期时间（秒）
CELERY_RESULT_EXPIRES=3600

# 是否扩展结果格式
CELERY_RESULT_EXTENDED=true

# Result Backend 传输选项
CELERY_RESULT_BACKEND_TRANSPORT_OPTIONS={}

# ========== Worker 配置 ==========

# Worker 执行池类型，可选: threads(线程池)、gevent(协程)、solo(单线程)
# threads: 适合IO密集型任务，gevent: 适合高并发场景
CELERY_WORKER_POOL=threads

# Worker 并发数（线程池大小），生产环境根据CPU核心数调整（推荐: CPU核心数*2-4）
# 对于 akshare 等外部 API 请求任务，建议设置为 1 以避免触发限流
CELERY_WORKER_CONCURRENCY=1

# 预取倍数，每个worker预取的任务数量 = 并发数 × 预取倍数
# 值越大worker越不容易空闲，但可能导致任务分配不均
# 对于外部 API 请求任务，建议设置为 1 以确保串行执行，避免并发触发限流
CELERY_WORKER_PREFETCH_MULTIPLIER=1

# 每个 Worker 进程处理的最大任务数，达到后重启进程（防止内存泄漏）
# 设置为0表示不限制，生产环境建议设置合理值（如1000-5000）
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000

# 是否禁用速率限制（true=禁用所有任务速率限制）
CELERY_WORKER_DISABLE_RATE_LIMITS=false

# Worker 日志格式（Python logging格式字符串，控制日志输出样式）
CELERY_WORKER_LOG_FORMAT="[%(asctime)s: %(levelname)s/%(processName)s] %(message)s"

# Worker 任务日志格式（与上述类似，额外包含任务相关信息）
CELERY_WORKER_TASK_LOG_FORMAT="[%(asctime)s: %(levelname)s/%(processName)s] [%(task_name)s(%(task_id)s)] %(message)s"

# Worker 日志级别（可选: DEBUG、INFO、WARNING、ERROR、CRITICAL）
# 生产环境建议 WARNING 或 ERROR 以减少日志量
CELERY_WORKER_LOGLEVEL=WARNING

# ========== 任务配置 ==========

# 默认队列名称（未指定队列的任务将发送到此队列）
CELERY_TASK_DEFAULT_QUEUE=default

# 默认交换机名称（RabbitMQ消息交换机）
CELERY_TASK_DEFAULT_EXCHANGE=default

# 默认路由键（用于将任务路由到指定队列）
CELERY_TASK_DEFAULT_ROUTING_KEY=default

# 默认速率限制（每个worker每秒执行的任务数），格式: "数量/秒"
# 留空表示不限制，示例: "10/s"(每秒10个)、"100/m"(每分钟100个)
CELERY_TASK_DEFAULT_RATE_LIMIT=""

# 默认硬超时时间（秒），任务执行超过此时间将被强制终止（3600秒 = 1小时）
CELERY_TASK_DEFAULT_TIME_LIMIT=3600

# 默认软超时时间（秒），任务执行超过此时间将抛出SoftTimeLimitExceeded异常（可被捕获处理）
# 应小于硬超时时间，3000秒 = 50分钟
CELERY_TASK_DEFAULT_SOFT_TIME_LIMIT=3000

# 默认最大重试次数（任务失败后自动重试的次数）
CELERY_TASK_DEFAULT_MAX_RETRIES=3

# 默认重试延迟（秒），任务失败后等待多久再重试
CELERY_TASK_DEFAULT_RETRY_DELAY=60

# 是否跟踪任务开始时间（启用后可记录任务开始执行的时间）
CELERY_TASK_TRACK_STARTED=true

# 是否延迟确认（启用后在任务执行完成后才确认，防止worker崩溃导致任务丢失）
# 推荐: 生产环境开启，可提高任务可靠性
CELERY_TASK_ACKS_LATE=true

# Worker丢失时是否拒绝任务（当worker异常退出时，是否将任务重新放回队列）
CELERY_TASK_REJECT_ON_WORKER_LOST=true

# 是否同步执行任务（仅用于测试，true=任务在调用线程同步执行，不发送到队列）
# 生产环境必须设置为 false
CELERY_TASK_ALWAYS_EAGER=false

# 同步执行时是否传播异常（仅当ALWAYS_EAGER=true时生效）
CELERY_TASK_EAGER_PROPAGATES=true

# ========== 序列化配置 ==========

# 任务序列化格式，可选: json、pickle、yaml、msgpack
# json: 安全但只支持基本类型，pickle: 支持Python对象但存在安全风险
# 生产环境必须使用 json 以确保安全
CELERY_TASK_SERIALIZER=json

# 结果序列化格式（建议与任务序列化保持一致）
CELERY_RESULT_SERIALIZER=json

# 接受的内容类型列表（用于安全验证，防止反序列化攻击）
# 生产环境应该只允许 json 类型
CELERY_ACCEPT_CONTENT=["json"]

# ========== 时区配置 ==========

# Celery 时区设置（建议与应用时区保持一致）
CELERY_TIMEZONE="Asia/Shanghai"

# 是否启用 UTC 时间（true=所有时间使用UTC，false=使用本地时区）
CELERY_ENABLE_UTC=true

# ========== 安全配置 ==========

# 是否发送任务发送事件（用于监控任务发送状态）
CELERY_TASK_SEND_SENT_EVENT=true

# 是否发送任务开始事件（用于监控任务执行开始）
CELERY_TASK_SEND_STARTED_EVENT=true

# 是否发送任务成功事件（用于监控任务执行成功）
CELERY_TASK_SEND_SUCCESS_EVENT=true

# 是否发送任务失败事件（用于监控任务执行失败）
CELERY_TASK_SEND_FAILURE_EVENT=true

# 是否发送任务重试事件（用于监控任务重试）
CELERY_TASK_SEND_RETRY_EVENT=true

# ========== Celery Beat 配置 ==========

# Beat 调度状态文件路径（用于持久化定时任务状态）
CELERY_BEAT_SCHEDULE_FILENAME=celerybeat-schedule

# Beat 最大循环间隔（秒），控制定时任务检查频率（5 = 每5秒检查一次）
CELERY_BEAT_MAX_LOOP_INTERVAL=5

# Beat 日志级别，可选: DEBUG、INFO、WARNING、ERROR、CRITICAL
# 生产环境建议 WARNING 或 ERROR
CELERY_BEAT_LOGLEVEL=WARNING

# Beat 调度器类型，可选: redbeat.RedBeatScheduler(Redis持久化)、celery.beat.PersistentScheduler(文件持久化)
# 生产环境建议使用 RedBeat 以支持分布式部署
CELERY_BEAT_SCHEDULER=redbeat.RedBeatScheduler

# ========== Flower 监控配置 ==========

# Flower 监控服务端口
CELERY_FLOWER_PORT=5555

# Flower 监听地址（0.0.0.0=允许外部访问，生产环境建议配置防火墙限制访问）
CELERY_FLOWER_HOST=0.0.0.0

# Flower 基本认证（格式: 用户名:密码，用于保护监控页面，生产环境必须修改！）
CELERY_FLOWER_BASIC_AUTH="admin:CHANGE_FLOWER_PASSWORD_IN_PRODUCTION"

# RabbitMQ Management API 地址（用于Flower获取队列信息）
CELERY_FLOWER_BROKER_API="http://localhost:15672/api/"

# ========== 任务模块配置 ==========

# 需要自动导入的任务模块列表（JSON格式，Celery启动时会自动注册这些模块中的任务）
CELERY_INCLUDE_JSON='["Modules.admin.tasks.default_tasks", "Modules.admin.queues.email_queues", "Modules.quant.queues.concept_queues", "Modules.quant.queues.industry_queues", "Modules.quant.queues.stock_queues"]'

# ========== 定时任务配置 ==========

# 定时任务调度配置（JSON格式，定义哪些任务需要定时执行）
# 格式: {"任务名": {"task": "任务路径", "schedule": 调度间隔(秒)或cron表达式}}
# schedule: 60.0 表示每60秒执行一次，也可使用crontab格式
CELERY_BEAT_SCHEDULE_JSON='{"task_print_hello": {"task": "Modules.admin.tasks.default_tasks.print_hello_task", "schedule": 60.0}}'

# ========== 任务队列配置 ==========

# 队列定义列表（JSON格式，定义系统中的所有队列）
# 每个队列包含: name(队列名)、exchange(交换机)、routing_key(路由键)
CELERY_TASK_QUEUES_JSON='[{"name": "default", "exchange": "default", "routing_key": "default"}, {"name": "email_queues", "exchange": "email_queues", "routing_key": "email_queues"},{"name": "quant_concept_queues", "exchange": "quant_concept_queues", "routing_key": "quant_concept_queues"},{"name": "quant_industry_queues", "exchange": "quant_industry_queues", "routing_key": "quant_industry_queues"},{"name": "quant_stock_queues", "exchange": "quant_stock_queues", "routing_key": "quant_stock_queues"}]'

# 任务路由配置（JSON格式，定义特定任务应该发送到哪个队列）
# 格式: {"任务路径": {"queue": "目标队列名"}}
CELERY_TASK_ROUTES='{"Modules.admin.queues.email_queues.send_batch_email_queue": {"queue": "email_queues"},"Modules.quant.queues.concept_queues.sync_concept_relation_queue": {"queue": "quant_concept_queues"},"Modules.quant.queues.industry_queues.sync_industry_relation_queue": {"queue": "quant_industry_queues"},"Modules.quant.queues.stock_queues.sync_stock_kline_1d_queue": {"queue": "quant_stock_queues"}}'

# ========== 其他配置 ==========

# 任务消息压缩算法，可选: gzip、bz2、zlib、lzma、空字符串(不压缩)
# 压缩可减少网络传输量，但会增加CPU开销
CELERY_TASK_COMPRESSION=""

# 任务消息压缩阈值（字节），超过此大小的消息才会压缩（1024字节 = 1KB）
CELERY_TASK_COMPRESSION_THRESHOLD=1024

# 结果压缩算法（设置同任务消息压缩）
CELERY_RESULT_COMPRESSION=""

# 结果压缩阈值（字节）
CELERY_RESULT_COMPRESSION_THRESHOLD=1024

# ========== FastAPI 集成配置 ==========

# 是否在FastAPI启动时验证Celery连接（true=连接失败则应用启动失败）
# 生产环境建议开启以确保依赖服务正常
CELERY_VERIFY_ON_STARTUP=true
