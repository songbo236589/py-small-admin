# ===================================================================
# Docker Compose 配置文件 - 生产环境
# ===================================================================
# 使用说明:
# 1. 复制根目录的 .env.production.example 为 .env.production: cp .env.production.example .env.production
# 2. 根据生产环境需求修改 .env.production 文件（特别是密码、密钥等敏感信息）
# 3. 启动所有服务: docker-compose -f docker-compose.prod.yml up -d
# 4. 查看日志: docker-compose -f docker-compose.prod.yml logs -f [service_name]
# 5. 停止所有服务: docker-compose -f docker-compose.prod.yml down
# ===================================================================

version: '3.8'

services:
  # ========================================
  # MySQL 数据库
  # ========================================
  mysql:
    image: mysql:8.0
    container_name: py-small-admin-mysql-prod
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: fastapi_db
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      TZ: Asia/Shanghai
    # 生产环境不暴露MySQL端口到主机，只在内网访问
    # ports:
    #   - "3306:3306"
    volumes:
      - mysql_data_prod:/var/lib/mysql
      - ./mysql-backups:/backups
      - ./mysql/my.cnf:/etc/mysql/conf.d/custom.cnf:ro
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --default-authentication-plugin=mysql_native_password
      - --max_connections=500
      - --innodb_buffer_pool_size=1G
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Redis 缓存
  # ========================================
  redis:
    image: redis:7-alpine
    container_name: py-small-admin-redis-prod
    restart: always
    # 生产环境不暴露Redis端口到主机
    # ports:
    #   - "6379:6379"
    volumes:
      - redis_data_prod:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # RabbitMQ 消息队列
  # ========================================
  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: py-small-admin-rabbitmq-prod
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: /
      TZ: Asia/Shanghai
    # 生产环境只暴露管理界面端口，AMQP端口不暴露
    ports:
      - "15672:15672" # 管理界面端口
    volumes:
      - rabbitmq_data_prod:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # FastAPI 应用服务
  # ========================================
  fastapi:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: py-small-admin-fastapi:latest
    container_name: py-small-admin-fastapi-prod
    restart: always
    environment:
      SERVICE_TYPE: fastapi
      APP_ENV: production
      APP_DEBUG: "false"
      APP_RELOAD: "false"
    env_file:
      - ../.env.production
    ports:
      - "8009:8009"
    volumes:
      - uploads_prod:/app/uploads
      - logs_prod:/app/logs
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8009/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Celery Worker (可扩展多个实例)
  # ========================================
  celery-worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: py-small-admin-celery-worker:latest
    container_name: py-small-admin-celery-worker-prod
    restart: always
    environment:
      SERVICE_TYPE: celery-worker
      APP_ENV: production
    env_file:
      - ../.env.production
    volumes:
      - uploads_prod:/app/uploads
      - logs_prod:/app/logs
    depends_on:
      - rabbitmq
      - redis
      - mysql
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Celery Beat (定时任务)
  # ========================================
  celery-beat:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: py-small-admin-celery-beat:latest
    container_name: py-small-admin-celery-beat-prod
    restart: always
    environment:
      SERVICE_TYPE: celery-beat
      APP_ENV: production
    env_file:
      - ../.env.production
    volumes:
      - logs_prod:/app/logs
    depends_on:
      - rabbitmq
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Flower 监控 (可选)
  # ========================================
  flower:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: py-small-admin-flower:latest
    container_name: py-small-admin-flower-prod
    restart: always
    environment:
      SERVICE_TYPE: flower
    env_file:
      - ../.env.production
    ports:
      - "5555:5555"
    depends_on:
      - rabbitmq
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Nginx 反向代理 (可选)
  # ========================================
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: py-small-admin-nginx-prod
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - uploads_prod:/app/uploads:ro
    depends_on:
      - fastapi
    networks:
      - py-small-admin-network-prod
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ========================================
# 数据卷定义
# ========================================
volumes:
  mysql_data_prod:
    driver: local
  redis_data_prod:
    driver: local
  rabbitmq_data_prod:
    driver: local
  uploads_prod:
    driver: local
  logs_prod:
    driver: local

# ========================================
# 网络定义
# ========================================
networks:
  py-small-admin-network-prod:
    driver: bridge
